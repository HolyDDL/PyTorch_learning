{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38303ba6",
   "metadata": {},
   "source": [
    "## PyTorch 基本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f079c86",
   "metadata": {},
   "source": [
    "* Tensor(张量)是PyTorch基本对象, 表示多维matrix,与NumPy中ndarray可以互换. 且使用方法类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d228f4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.],\n",
       "        [12., 13., 14.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "px = range(15)\n",
    "tx = torch.Tensor(px) #从已有list创建Tensor\n",
    "tx = tx.reshape(5,3)\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9170421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 9., 10., 11.],\n",
       "       [12., 13., 14.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "nx = tx.numpy() #从tensor转换为numpy\n",
    "nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9276318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.],\n",
       "        [12., 13., 14.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty = torch.from_numpy(nx) #从numpy转化为tensor\n",
    "ty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25b192",
   "metadata": {},
   "source": [
    "* 以下Variable已被停用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e3268",
   "metadata": {},
   "source": [
    ">* Variable是Tensor的封装, 用于放入计算图中进行向前转播, 反向传播和自动求导. Variable有三个基本属性, data:包含的Tensor数据部分; grad传播方向的梯度,这个属性是延迟分配的且只允许进行一次; creator:创建这个Variable的Function引用,用于回溯整个链路,若是用户创建的Variable,creator为None,同时这种Variable称作Leaf Variable.autograd只会给Leaf Variable分配梯度."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c174fb",
   "metadata": {},
   "source": [
    ">* Tensor 不能反向传播, Variable可以反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "107d7bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m(x,requires_grad \u001b[38;5;241m=\u001b[39m true)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'variable'"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4)\n",
    "var = torch.variable(x,requires_grad = true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a428f",
   "metadata": {},
   "source": [
    "### 模型的保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896046b",
   "metadata": {},
   "source": [
    "torch.save(model,'model.pkl')  #保存model,''内为名字\n",
    "\n",
    "model = torch('model.pkl')   #加载模型\n",
    "\n",
    "torch.save(model.state_dict(),'params.pkl')  #保存网络参数\n",
    "\n",
    "model.load_state_dict(torch.load('params.pkl')  #加载网络参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbc6f1",
   "metadata": {},
   "source": [
    "###### 在torchvision.models中, PyTorch提供了常用模型:\n",
    "* AlexNet\n",
    "* VGG\n",
    "* ResNet\n",
    "* SqueezeNet\n",
    "* DenseNet\n",
    "* Inception v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8b1f3",
   "metadata": {},
   "source": [
    "可以使用torch.util.model_zoo来预加载, 具体通过设置参数pretrained = True来实现\n",
    "\n",
    " 只加载模型，不加载预训练参数 如果只需要网络结构，不需要训练模型的参数来初始化，可以将pretrained = False(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbe7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3377f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d8c23",
   "metadata": {},
   "source": [
    "## Dataset使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc84120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset #导入Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d1e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f972a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "class myData(Dataset): #继承Dataset类\n",
    "    \n",
    "    def __init__(self,data_dir,label_dir): #初始化函数用于加载数据集\n",
    "        self.data_dir = data_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_path_list = os.listdir(self.data_dir) #不必在此直接读取数据, 减少内存负担\n",
    "        self.label_path_list = os.listdir(self,label_dir)\n",
    "        \n",
    "    def __getitem__(self,idx): #重写__getitem__方法, 用于返回idx索引所在的单个的sample和label\n",
    "        img_name = self.img_path_list[idx]\n",
    "        label_name = self.label_path_list[idx]\n",
    "        img_item_path = os.path.join(self.data_dir,self.img_name) #加载图像的路经\n",
    "        label_item_path = os.path.join(self.label_dir,self.label_name) #加载label路径\n",
    "        img = cv2.imread(img_item_path)    #读取图片\n",
    "        with open(label_item_path) as f:  #读取标签\n",
    "            label = f.read()\n",
    "        return img,label \n",
    "    def __len__(self): #重写__len__方法, 用于返回数据集长度\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0e9b4",
   "metadata": {},
   "source": [
    "## TensorBoard 使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d55a2e",
   "metadata": {},
   "source": [
    "* writer.add_scalar()方法绘制标量图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b85f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter #导入tensorboard的summarywriter类\n",
    "\n",
    "\n",
    "writer = SummaryWriter('logs') #创建实例,存储event在logs文件夹\n",
    "\n",
    "# writer.add_image() #添加图片\n",
    "for each in range(100):\n",
    "    writer.add_scalar('y=2x',2*each,each) #添加标量\n",
    "writer.close()\n",
    "'''def add_scalar(\n",
    "        self,\n",
    "        tag,            #图像的title\n",
    "        scalar_value,   #图像的y轴数据\n",
    "        global_step=None, #图像的x轴数据\n",
    "        walltime=None,  \n",
    "        new_style=False,\n",
    "        double_precision=False,\n",
    "    )\n",
    "\n",
    "    Args:\n",
    "            tag (string): Data identifier\n",
    "            scalar_value (float or string/blobname): Value to save\n",
    "            global_step (int): Global step value to record\n",
    "            walltime (float): Optional override default walltime (time.time())\n",
    "              with seconds after epoch of event\n",
    "            new_style (boolean): Whether to use new style (tensor field) or old\n",
    "              style (simple_value field). New style could lead to faster data loading.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b586a",
   "metadata": {},
   "source": [
    "上述命令将创建tensorboard的一个event\n",
    "\n",
    "打开tensorboard\n",
    "\n",
    "用terminal进入logs父路径, 输入**tensorboard --logdir=logs --port=6007**(可选, 默认打开一个主机网页, 端口号为6006,此处可更改端口号)即可打开tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97839bd",
   "metadata": {},
   "source": [
    "* writer.add_image()绘制单个图像图像, 使用 writer.add_images()绘制多个图像, 其中,图片参数数组为4维度,某张×高×宽×channel, step仍需循环加入(多次图片组读取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f10ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter #导入tensorboard的summarywriter类\n",
    "import cv2\n",
    "\n",
    "writer = SummaryWriter('logs') #创建实例,存储event在logs文件夹\n",
    "\n",
    "img_list = ['bue_78.png','img_002.jpg']\n",
    "i = 1\n",
    "for each in img_list:\n",
    "  img = cv2.imread(each)\n",
    "  writer.add_image('imgtitle',img,i,dataformats='HWC')\n",
    "  i = i + 1\n",
    "  print(i)\n",
    "writer.close()\n",
    "\n",
    "'''def add_image(\n",
    "        self,\n",
    "         tag,   #加载窗口的title\n",
    "         img_tensor, #图片数组数据\n",
    "         global_step=None, #数据步骤,若title相同, 可通过更改step,使之产生一定区别\n",
    "          walltime=None, \n",
    "          dataformats=\"CHW\" #图片数组形状, 3(RGB)*640(高)*720(宽), 可以通过令为HWC变成640*720*3加载. opencv为HWC的numpy.array形\n",
    "    ):\n",
    "        \"\"\"Add image data to summary.\n",
    "\n",
    "        Note that this requires the ``pillow`` package.\n",
    "\n",
    "        Args:\n",
    "            tag (string): Data identifier\n",
    "            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data\n",
    "            global_step (int): Global step value to record\n",
    "            walltime (float): Optional override default walltime (time.time())\n",
    "              seconds after epoch of event\n",
    "            dataformats (string): Image data format specification of the form\n",
    "              CHW, HWC, HW, WH, etc.\n",
    "        Shape:\n",
    "            img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to\n",
    "            convert a batch of tensor into 3xHxW format or call ``add_images`` and let us do the job.\n",
    "            Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitable as long as\n",
    "            corresponding ``dataformats`` argument is passed, e.g. ``CHW``, ``HWC``, ``HW``.\n",
    "            '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7490a",
   "metadata": {},
   "source": [
    "* 输出神经网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6137b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_graph(model, input_to_model=None, verbose=False, use_strict_trace=True)\n",
    "'''\n",
    "    Args:\n",
    "        model (torch.nn.Module) = Model to draw. #需要画出结构图的模型实例\n",
    "        input_to_model (torch.Tensor or list of torch.Tensor) = A variable or a tuple of variables to be fed. #输入神经网络的输入Tensor\n",
    "        verbose (bool) = Whether to print graph structure in console. #是否在Terminal输出图像\n",
    "        use_strict_trace (bool) = Whether to pass keyword argument strict to torch.jit.trace. \n",
    "                            Pass False when you want the tracer to record your mutable container types (list, dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdae17b",
   "metadata": {},
   "source": [
    "## DataLoader使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8113c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = 'xx'\n",
    "test_loader = DataLoader(dataset,batch_size=4,shuffle=True,drop_last=True) #通过DataLoader实例载入Dataset\n",
    "\n",
    "for epoch in range(2): #加载两轮数据,可以在轮数内进行ANN训练\n",
    "  for data in test_loader: #从test_loader里面加载数据包,\n",
    "                            #data是一个list, 里面有imgs和labels \n",
    "                            #imgs是一个4维数组, labels是一个list,里面写有相应的sample的label\n",
    "    imgs,labels = data \n",
    "    #可以在此对imgs和labels做一些事情\n",
    "\n",
    "''' Args:\n",
    "        dataset (Dataset): dataset from which to load the data.   #要加载的数据集\n",
    "        batch_size (int, optional): how many samples per batch to load   #一次加载几张作为一个包,default= 1\n",
    "            (default: ``1``).\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled  #是否打乱从数据集里面加载的顺序\n",
    "            at every epoch (default: ``False``).\n",
    "        sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
    "            samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
    "            implemented. If specified, :attr:`shuffle` must not be specified.\n",
    "        batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
    "            returns a batch of indices at a time. Mutually exclusive with\n",
    "            :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
    "            and :attr:`drop_last`.\n",
    "        num_workers (int, optional): how many subprocesses to use for data        #加载的子进程数, windows有bug只能为0,只有主进程\n",
    "            loading. ``0`` means that the data will be loaded in the main process.\n",
    "            (default: ``0``)\n",
    "        collate_fn (callable, optional): merges a list of samples to form a\n",
    "            mini-batch of Tensor(s).  Used when using batched loading from a\n",
    "            map-style dataset.\n",
    "        pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
    "            into device/CUDA pinned memory before returning them.  If your data elements\n",
    "            are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
    "            see the example below.\n",
    "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,      #如果最后一个包不满足指定的数据数目,是否舍弃掉最后一个包\n",
    "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
    "            the size of dataset is not divisible by the batch size, then the last batch\n",
    "            will be smaller. (default: ``False``)\n",
    "        timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
    "            from workers. Should always be non-negative. (default: ``0``)\n",
    "        worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
    "            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
    "            input, after seeding and before data loading. (default: ``None``)\n",
    "        generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
    "            by RandomSampler to generate random indexes and multiprocessing to generate\n",
    "            `base_seed` for workers. (default: ``None``)\n",
    "        prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
    "            in advance by each worker. ``2`` means there will be a total of\n",
    "            2 * num_workers batches prefetched across all workers. (default: ``2``)\n",
    "        persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
    "            the worker processes after a dataset has been consumed once. This allows to\n",
    "            maintain the workers `Dataset` instances alive. (default: ``False``)\n",
    "        pin_memory_device (str, optional): the data loader will copy Tensors\n",
    "            into device pinned memory before returning them if pin_memory is set to true.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1a774",
   "metadata": {},
   "source": [
    "## nn骨架搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e7848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前向算法处理以后的input\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Model(nn.Module):  #创建神经网络骨架, 一定要重写__init__和forward函数\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__() #继承父类\n",
    "        #在下做一些神经网络基础设定\n",
    "        #xxxxx\n",
    "        #xxxxx\n",
    "    \n",
    "    def forward(self, input):   #前向算法布置\n",
    "        #布置前向算法\n",
    "        output = '前向算法处理以后的input'\n",
    "        return output\n",
    "\n",
    "ann = Model()   #创建神经网络实例\n",
    "input = torch.Tensor([1.0,2.0]) #传入Tensor型输入\n",
    "output = ann(input) #前向算法通过实例直接调用\n",
    "\n",
    "print(output) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb0fcc",
   "metadata": {},
   "source": [
    "## 卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69812e3",
   "metadata": {},
   "source": [
    "从一个输入的张量(大的高和宽), 与kernel张量(小的高和宽)从头开始相匹配, 对应元素相乘并全部相加得到一个标量. 然后这个kernel再进行移动, 与input张量的其他数相匹配, 得到其他标量, 直到取完input张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c3f48",
   "metadata": {},
   "source": [
    "每一个Kernel相当于是图片在某一个维度上的特征, 训练模型将自动提取这一特征而不需要人手动提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ed1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[22, 19, 16],\n",
      "          [21, 14, 18],\n",
      "          [18, 19, 14]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#设置2d卷积操作\n",
    "# torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
    "'''    Args:\n",
    "        input = input tensor of shape (minibatch ,in_channels , iH , iW) #输入张量需要四个size, minibatch:子集个数, in_channels:通道个数\n",
    "                                                                            iH:张量的高, iW:张量的宽\n",
    "        weight = filters of shape (out_channels, in_channels/groups ,kH ,kW) #输入卷积核kernel, out_channels:输出通道个数, \n",
    "                                                                            in_channels/groups:输入通道个数(groups一般为1),\n",
    "                                                                             kH:张量的高, kW:张量的宽\n",
    "        bias = optional bias tensor of shape(out_channel) #偏置\n",
    "        stride = the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 #卷积核一次移动多少数据,\n",
    "                                                                                            可以通过标量或者元组指定.默认为1\n",
    "        padding = implicit paddings on both sides of the input.Can be a string {'valid', 'same'}, #扩充输入张量的每一个高宽维度\n",
    "                    single number or a tuple (padH, padW). Default: 0                             #输入标量或者高宽元组\n",
    "                    padding='valid' is the same as no padding.                                   \n",
    "                    padding='same' pads the input so the output has the same shape as the input.\n",
    "                    However, this mode doesn't support any stride values other than 1.    \n",
    "        dilation = the spacing between kernel elements. Can be a single number or a tuple (dH, dW). Default: 1 #kernel中的元素间隔, \n",
    "                                                                                                                用于空洞卷积\n",
    "        groups = split input into groups, in_channels should be divisible by the number of groups. Default: 1                                                                        \n",
    "    '''\n",
    "input = torch.tensor([[0,1,2,3,4],\n",
    "                      [3,2,1,0,4],\n",
    "                      [4,3,2,1,0],\n",
    "                      [2,1,3,4,0],\n",
    "                      [3,2,1,4,0]]) #输入张量为(5,5)型\n",
    "kernel = torch.tensor([[0,1,2],\n",
    "                       [1,2,0],\n",
    "                       [2,0,1]])#kernel为(3,3)型\n",
    "#以下重置两个张量为合法形式\n",
    "input = torch.reshape(input,(1,1,5,5))\n",
    "kernel = torch.reshape(kernel,(1,1,3,3))\n",
    "#end\n",
    "\n",
    "output = F.conv2d(input,kernel,stride=1) #2d卷积\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7c6eb",
   "metadata": {},
   "source": [
    "*卷积实例*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class Model(nn.Module): #定义卷积神经网络\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,stride=1,padding=0)#设置卷积层相应参数\n",
    "\n",
    "    def forward(self,input):#设置前向算法 \n",
    "        output = self.conv1(input)\n",
    "        return output\n",
    "\n",
    "ann = Model() #实例化神经网络\n",
    "img_path = 'bue_78.png'\n",
    "img = cv2.imread(img_path)\n",
    "img_chw = np.transpose(img,(2,0,1)) #将HWC格式的ndarrary图片,转化成CHW型, 数字代表索引将要变化成为的值 \n",
    "img_chw = img_chw[np.newaxis] #给CHW型图片加一个维度, 使之符合卷积格式要求\n",
    "input = torch.from_numpy(img_chw).float() #卷积需要数据为浮点型\n",
    "writer = SummaryWriter('logs') #加载tensorborad可视化图像\n",
    "output = ann(input) #调用神经网络前向算法, 得到卷积后的图像\n",
    "print(output.shape)\n",
    "output = torch.reshape(output,(-1,3,838,800))\n",
    "writer.add_image('input',img,dataformats='HWC')\n",
    "writer.add_image('output1',output[0])\n",
    "writer.add_image('output2',output[1])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd27eb",
   "metadata": {},
   "source": [
    "## 最大池化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98680a",
   "metadata": {},
   "source": [
    "对于一个Tensor, 使用最大池化核kernel去从头开始匹配, 取得这个kernel覆盖下的tensor最大值标量, 存为output里的一个元素, 直到取完."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d661c",
   "metadata": {},
   "source": [
    "*池化实例*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "'''\n",
    "    Args:\n",
    "        kernel_size = the size of the window to take a max over #池化核的大小\n",
    "        stride = the stride of the window. Default value is kernel_size #kernel步进大小, 默认为kernel的大小\n",
    "        padding = implicit zero padding to be added on both sides #扩张原Tensor\n",
    "        dilation = a parameter that controls the stride of elements in the window #kernel的空洞\n",
    "        return_indices = if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later\n",
    "        ceil_mode = when True, will use ceil instead of floor to compute the output shape #是否在池化核越出Tensor范围时候继续池化剩下的\n",
    "''' \n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=128,stride=3,padding=0,ceil_mode=True)\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.pool(input)\n",
    "        return output\n",
    "\n",
    "ann = Model()\n",
    "img_path = 'bue_78.png'\n",
    "img = cv2.imread(img_path)\n",
    "img_chw = np.transpose(img,(2,0,1)) #将HWC格式的ndarrary图片,转化成CHW型, 数字代表索引将要变化成为的值 \n",
    "img_chw = img_chw[np.newaxis] #给CHW型图片加一个维度, 使之符合池化格式要求\n",
    "input = torch.from_numpy(img_chw).float()\n",
    "writer = SummaryWriter('logs')\n",
    "output = ann(input)\n",
    "writer.add_image('input',img_chw[0])\n",
    "writer.add_image('output',output[0])\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a28f91",
   "metadata": {},
   "source": [
    "## 非线性激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e7aacb",
   "metadata": {},
   "source": [
    "使用不同的函数对数据进行非线性变化, 产生一组新的张量, 可以提高神经网络的泛化性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5ce2f",
   "metadata": {},
   "source": [
    "常用非线性激活函数:\n",
    "\n",
    "ReLU\n",
    "\n",
    "Sigmod等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded79403",
   "metadata": {},
   "source": [
    "*非线性激活实例*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#for example:\n",
    "# nn.ReLU(inplace=False)\n",
    "'''\n",
    "    Args:\n",
    "        Input: (*), where * means any number of dimensions. #输入可以为任意\n",
    "        Output: (*), same shape as the input. #输出也为任意\n",
    "        inplace = can optionally do the operation in-place. Default: False #是否将处理后的值覆盖原值, 默认不覆盖\n",
    "'''\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid() #使用Sigmoid激活函数\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.sigmoid(input)\n",
    "        return output\n",
    "\n",
    "ann = Model()\n",
    "img_path = 'bue_78.png'\n",
    "img = cv2.imread(img_path)\n",
    "img_chw = np.transpose(img,(2,0,1)) #将HWC格式的ndarrary图片,转化成CHW型, 数字代表索引将要变化成为的值 \n",
    "img_chw = img_chw[np.newaxis] #给CHW型图片加一个维度, 使之符合格式要求\n",
    "input = torch.from_numpy(img_chw)\n",
    "output = ann(input)\n",
    "writer = SummaryWriter('logs')\n",
    "writer.add_image('input',img_chw[0])\n",
    "writer.add_image('output',output[0])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5921f",
   "metadata": {},
   "source": [
    "## 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8929f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)\n",
    "'''\n",
    "    Args:\n",
    "        num_features = C from an expected input of size (N, C, H, W) #在输入四个size中的channel数目\n",
    "        eps = a value added to the denominator for numerical stability. Default: 1e-5\n",
    "        momentum = the value used for the running_mean and running_var computation. \n",
    "                Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1\n",
    "        affine = a boolean value that when set to True, this module has learnable affine parameters. Default: True\n",
    "        track_running_stats = a boolean value that when set to True, this module tracks the running mean and variance, \n",
    "                        and when set to False, this module does not track such statistics, \n",
    "                        and initializes statistics buffers running_mean and running_var as None. \n",
    "                        When these buffers are None, this module always uses batch statistics. in both training and eval modes. \n",
    "                        Default: True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a71558",
   "metadata": {},
   "source": [
    "## 线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "'''\n",
    "    Args:\n",
    "        in_features = size of each input sample  #输入神经元个数\n",
    "        out_features = size of each output sample #输出神经元个数\n",
    "        bias = If set to False, the layer will not learn an additive bias. Default: True #是否具有偏置\n",
    "'''\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = nn.Linear(2021040,20)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.linear(input)\n",
    "        return output\n",
    "ann = Model()\n",
    "img_path = 'bue_78.png'\n",
    "img = cv2.imread(img_path)\n",
    "img_chw = np.transpose(img,(2,0,1)) #将HWC格式的ndarrary图片,转化成CHW型, 数字代表索引将要变化成为的值 \n",
    "img_chw = img_chw[np.newaxis] #给CHW型图片加一个维度, 使之符合格式要求\n",
    "input = torch.from_numpy(img_chw).float()\n",
    "input = torch.flatten(input) #使用展平函数将input展为一维数组\n",
    "print(input.shape)\n",
    "output = ann(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13196830",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631efb8",
   "metadata": {},
   "source": [
    "用于在初始化中初始化一系列模型, 在后续前向算法调用时可以直接调用Sequential的实例而不需一个一个调用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a899d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.model = nn.Sequential( #定义一个线性模型队列\n",
    "            nn.Conv2d(3,32,5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(), #用于将数据展开为一维数据方便线性层处理\n",
    "            nn.Linear(1024,32),\n",
    "            nn.Linear(32,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "    \n",
    "ann = Model()\n",
    "print(ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ae5d6",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bd45c",
   "metadata": {},
   "source": [
    "有各种各样的损失函数, 具体使用查用PyTorch官网描述\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1ebec",
   "metadata": {},
   "source": [
    "使用时, 先创建类的实例, 再通过类的实例去传入output和label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.MSEloss()\n",
    "\n",
    "result = Loss(output,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12555939",
   "metadata": {},
   "source": [
    "## BackWard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc65d0",
   "metadata": {},
   "source": [
    "对损失函数使用.backward()求梯度. 便于以后优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767129e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.MSEloss()\n",
    "\n",
    "result = Loss(output,label)\n",
    "\n",
    "result.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bc070",
   "metadata": {},
   "source": [
    "## Optimizer 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9381a55",
   "metadata": {},
   "source": [
    "用于对模型中的参数进行调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = datasets.CIFAR10('dataset',train=False,transform=transforms.ToTensor(),download=True)\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.NetualNet = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.NetualNet(input)\n",
    "        return output\n",
    "\n",
    "ANN = Model()\n",
    "writer = SummaryWriter('logs')\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim = optim.SGD(ANN.parameters(),lr=0.01) #创建一个优化器, 使用SGD优化(随机梯度下降)\n",
    "for epoch in range(50):                    #一共训练50轮\n",
    "    epoch_loss = 0.0                        #每轮损失函数值\n",
    "    print('Now we are in epoch NO.{}'.format(epoch))\n",
    "    i = 0\n",
    "    for data in dataloader:                #数据集中图片分别加载\n",
    "        imgs,labels = data\n",
    "        output = ANN(imgs)\n",
    "        result_loss = loss(output,labels)\n",
    "        optim.zero_grad()                   #重要!!!!!!在进行优化前先将优化器梯度归零\n",
    "        result_loss.backward()              #求梯度\n",
    "        optim.step()                        #反向传播优化\n",
    "        epoch_loss = epoch_loss + result_loss #每个图像的损失叠加\n",
    "        print('Image number is {}'.format(i))\n",
    "        print(f\"This image's loss is {result_loss}\")\n",
    "        i = i + 1 \n",
    "    writer.add_scalar('Epoch loss',epoch_loss,epoch)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81ad2f",
   "metadata": {},
   "source": [
    "## 现有模型修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "vgg_add = torchvision.models.vgg16(weights=None) #加载已有模型\n",
    "print(vgg_add) #打印已有模型结构\n",
    "\n",
    "vgg_add.add_module('add',nn.Linear(1000,10)) #加入一个线性层在整个分类最外面\n",
    "vgg_add.classifier.add_module('addTOclas',nn.Linear(1000,10)) #加入到classifier序列层中\n",
    "print(vgg_add)\n",
    "\n",
    "vgg_change = torchvision.models.vgg16(weights=None)\n",
    "\n",
    "vgg_change.classifier[6] = nn.Linear(4096,10) #将vgg的classifier层中第[6]位层更改\n",
    "print(vgg_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7302a58",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "vgg16 = torchvision.models.vgg16(weights=None) #加载已有模型\n",
    "  \n",
    "torch.save(vgg16,'vgg16_mothed1.pt') #保存vgg16所有, 包括参数以及网络结构\n",
    "\n",
    "torch.save(vgg16.state_dict(),'vgg16_mothed2.pt') #只保存vgg16参数为有序字典形式\n",
    "\n",
    "class Model(nn.Module): #自定义神经网络\n",
    "\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,64,3)\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.conv(input)\n",
    "        return output\n",
    "ann = Model()\n",
    "torch.save(ann,'mymodel.pt') #保存全模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208aa79",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from save_model import Model  #将自己的模型引入, 以免加载模型时出错\n",
    "\n",
    "\n",
    "vgg = torch.load('vgg16_mothed1.pt') #加载第一种全方式保存的模型\n",
    "print(vgg)\n",
    "\n",
    "#第二种方式加载时, 一定要先创建模型, 然后再加载数值\n",
    "new_vgg = torchvision.models.vgg16(weights=None)  #加载模型\n",
    "new_vgg.load_state_dict(torch.load('vgg16_mothed2.pt')) # 加载参数\n",
    "print(new_vgg)\n",
    "\n",
    "#加载自己的模型时, 一定要先引入定义时的神经网络类, \n",
    "#随后才能正确加载, 否则将会报错\n",
    "mymodel = torch.load('mymodel.pt')\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070401fc",
   "metadata": {},
   "source": [
    "## 利用GPU训练与训练完整套路\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#判断环境是否用GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#加载数据集\n",
    "test_data = torchvision.datasets.CIFAR10('test_dataset',train=False,transform=torchvision.transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "train_data = torchvision.datasets.CIFAR10('train_dataset',train=True,transform=torchvision.transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "tran_loader = DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "#得到并打印数据集大小\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(f'训练数据集大小为: {train_data_size}')\n",
    "print(f'测试数据集大小为: {test_data_size}')\n",
    "\n",
    "#引入TensorBoard记录数据\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "#创建模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mymodel = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,input): \n",
    "        output = self.mymodel(input)\n",
    "        return output \n",
    "\n",
    "#创建网络实例\n",
    "ann = Model()\n",
    "ann.to(device=device) #将神经网络移动到GPU上, 此步不需要重新赋值\n",
    "\n",
    "#创建LossFunction(交叉熵)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device) #将损失函数移动到GPU上, 此步不需要重新赋值\n",
    "\n",
    "#创建优化器(随机梯度下降优化器)\n",
    "learning_rate = 1e-2\n",
    "optim = torch.optim.SGD(ann.parameters(),lr=learning_rate)\n",
    "\n",
    "#训练过程\n",
    "ann.train() #神经网络进入训练模式, 一些特殊的层需要先进入训练模式\n",
    "epoch = 10\n",
    "all_roll = 0\n",
    "for i in range(epoch):\n",
    "\n",
    "    all_loss = 0\n",
    "    print(f'******现在在第 {i} 轮训练******')\n",
    "    for data in tran_loader:\n",
    "        imgs, labels = data\n",
    "        #将训练数据放到GPU上,此处一定要重新赋值\n",
    "        imgs = imgs.to(device)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.to(device)\n",
    "        #end\n",
    "        output = ann(imgs)\n",
    "        loss = loss_fn(output,labels)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        all_roll = all_roll + 1\n",
    "        if all_roll % 100 == 0:\n",
    "            print(f'训练轮次: {all_roll} ,损失: {loss}')\n",
    "        all_loss = all_loss + loss\n",
    "    print(f'本轮总训练损失：{all_loss.item()}')#去除Tensor数据类型, 直接打印数值\n",
    "    writer.add_scalar('train_loss',all_loss,i) \n",
    "    #训练验证\n",
    "    ann.eval() #神经网络进入验证模式\n",
    "    with torch.no_grad(): #去除自动微分, 防止验证时干扰反向传播\n",
    "        all_test_loss = 0\n",
    "        all_accurate = 0\n",
    "        for data in test_loader:\n",
    "            imgs, labels = data \n",
    "            #迁移到GPU\n",
    "            imgs = imgs.to(device)\n",
    "            labels = torch.tensor(labels)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            out_test = ann(imgs)\n",
    "            loss_test = loss_fn(out_test, labels)\n",
    "            all_test_loss = all_test_loss + loss_test\n",
    "\n",
    "            '''\n",
    "                求准确率时用argmax()函数, 返回一个数组中最大的值的下标\n",
    "                torch.argmax(input, dim, keepdim=False) → LongTensor\n",
    "                Args:\n",
    "                    input (Tensor) = the input tensor. #输入Tensor张量\n",
    "                    dim (int) = the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
    "                                                        #求最大标的维数, 0是高, 1是宽\n",
    "                    keepdim (bool) = whether the output tensor has dim retained or not. Ignored if dim=None.                                   \n",
    "            '''\n",
    "            accurate = torch.argmax(out_test,1)\n",
    "            all_accurate =all_accurate + (accurate == labels).sum() #bollean表达式返回一个True(1)和False(0)列表, .sum()求和\n",
    "\n",
    "        accurate_rate = all_accurate/test_data_size\n",
    "        print(f'验证损失: {all_test_loss}')\n",
    "        print(f'验证准确率为: {accurate_rate*100:.2f}%')\n",
    "        writer.add_scalar('test_loss',all_test_loss,i)\n",
    "        writer.add_scalar('accurate_rate',accurate_rate,i)\n",
    "    #模型保存\n",
    "    torch.save(ann.state_dict(),'LAST.pt') #最后一轮训练的参数模型\n",
    "        #将用来保存损失最小的模型\n",
    "    if i == 0:\n",
    "        torch.save(ann.state_dict(),'BEST.pt')\n",
    "        judge_loss = all_test_loss\n",
    "    if all_test_loss < judge_loss:\n",
    "        judge_loss = all_test_loss\n",
    "        torch.save(ann.state_dict(),'BEST.pt')\n",
    "        print(f'现在训练最好的轮数是: {i}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30092d6c",
   "metadata": {},
   "source": [
    "## 神经网络模型的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import torch\n",
    "from train import Model  #引入自己的模型\n",
    "\n",
    "img = cv2.imread('horse1.jpg')\n",
    "img = cv2.resize(img,(32,32))  #重置图片大小, 使之符合进模型条件格式\n",
    "while 1:\n",
    "    cv2.imshow('resize',img)\n",
    "    c = cv2.waitKey() & 0xff\n",
    "    if c == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "img = np.transpose(img,(2,0,1))\n",
    "img = img[np.newaxis,...] #重设图片维度, 使之符合格式\n",
    "img = torch.from_numpy(img).float()\n",
    "label_dict = {'airplane':0,'automobile':1,'bird':2,'cat':3,'deer':4,'dog':5,'frog':6,\n",
    "                'horse':7,'ship':8,'truck':9}\n",
    "\n",
    "weight = 'from_colab/BEST.pt'\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(weight,map_location='cpu')) #加载模型, map_location: 将模型从CUDA映射到CPU上\n",
    "\n",
    "model.eval() # 设置模型测试模式\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "print(output)\n",
    "for k,v in label_dict.items():\n",
    "    if v == torch.argmax(output).item():\n",
    "        print(k)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
